"""
## 1) Explora√ß√£o dos dados
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

print("--- 1. Carregamento e Explora√ß√£o Inicial ---")
print("Carregando o dataset 'data.csv'...")

try:
    df = pd.read_csv('breast-cancer.csv')
except FileNotFoundError:
    print("ERRO: O arquivo 'data.csv' n√£o foi encontrado. Verifique o caminho.")
    exit()

print("\n1.1. As 5 primeiras linhas do dataset:")
print(df.head())

print("\n--- 2. Informa√ß√µes Gerais e Estat√≠sticas Descritivas ---")

print("\n2.1. Informa√ß√µes Gerais do DataFrame (.info()):")
df.info()

print("\n2.2. Estat√≠sticas Descritivas das Colunas Num√©ricas (.describe()):")
print(df.describe().T) 

print("\n--- 3. Verifica√ß√£o de Valores Nulos e Duplicados ---")

print("\n3.1. Contagem de Valores Nulos:")
null_counts = df.isnull().sum()
print(null_counts[null_counts > 0]) 

print(f"\n3.2. Total de linhas duplicadas: {df.duplicated().sum()}")

print("\n--- 4. An√°lise da Distribui√ß√£o da Vari√°vel Alvo ('diagnosis') ---")

target_counts = df['diagnosis'].value_counts()
print("\n4.1. Distribui√ß√£o de Frequ√™ncia da 'diagnosis':")
print(target_counts)

plt.figure(figsize=(7, 5))
sns.countplot(x='diagnosis', data=df, palette='pastel')
plt.title('Distribui√ß√£o de Tumores (Benignos vs. Malignos)')
plt.xlabel('Diagnosis (M=Maligno, B=Benigno)')
plt.ylabel('Contagem')
plt.grid(axis='y', alpha=0.5)
plt.show()

total = target_counts.sum()
pct_malignant = (target_counts['M'] / total) * 100
pct_benign = (target_counts['B'] / total) * 100

print(f"4.2. Porcentagem de Malignos (M): {pct_malignant:.2f}%")
print(f"Porcentagem de Benignos (B): {pct_benign:.2f}%")

print("\n--- 5. Identifica√ß√£o e Prepara√ß√£o de Vari√°veis (Features e Alvo) ---")

cols_to_drop = ['id'] 
df_clean = df.drop(columns=cols_to_drop)
print(f"Colunas removidas: {cols_to_drop}")

df_clean['diagnosis_encoded'] = df_clean['diagnosis'].map({'M': 1, 'B': 0})
# M (Maligno) -> 1
# B (Benigno) -> 0

# Vari√°veis Preditoras (Features)
# X: Todas as colunas num√©ricas (Features)
X = df_clean.drop(columns=['diagnosis', 'diagnosis_encoded'])

# Vari√°vel Alvo
# Y: Coluna 'diagnosis_encoded' (Alvo)
Y = df_clean['diagnosis_encoded']

print("\n5.4. Resultado da Separa√ß√£o:")
print(f"Vari√°vel Alvo (Y): {Y.name}")
print(f"Shape de X (Preditoras): {X.shape}")
print(f"Shape de Y (Alvo): {Y.shape}")
print("\nPrimeiras 3 Linhas das Features (X):")
print(X.head(3))
print("\nPrimeiras 3 Linhas do Alvo Codificado (Y):")
print(Y.head(3))

"""## 2) Pr√©-processamento dos Dados

"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
import warnings

warnings.filterwarnings('ignore')

print("--- 1. Carregamento e Limpeza Inicial dos Dados ---")

try:
    df = pd.read_csv('breast-cancer.csv')
except FileNotFoundError:
    print("ERRO: O arquivo 'data.csv' n√£o foi encontrado. Certifique-se de que est√° no diret√≥rio correto.")
    exit()

cols_to_drop = ['id']
df_clean = df.drop(columns=cols_to_drop)

print(f"Colunas removidas: {cols_to_drop}")
print(f"Shape do DataFrame ap√≥s limpeza: {df_clean.shape}")

print("\n--- 2. Convers√£o da Vari√°vel Alvo para Bin√°rio ---")

df_clean['diagnosis_encoded'] = df_clean['diagnosis'].map({'M': 1, 'B': 0})

X = df_clean.drop(columns=['diagnosis', 'diagnosis_encoded'])
Y = df_clean['diagnosis_encoded']

print(f"Alvo 'diagnosis' mapeado para 1 (M) e 0 (B).")
print(f"Vari√°vel Alvo (Y) definida: {Y.name}")
print(f"N√∫mero de Vari√°veis Preditoras (X): {X.shape[1]}")

print("\n--- 3. Separa√ß√£o de Dados em Treino e Teste (70/30) ---")

# Usando 70% para treino e 30% para teste (dentro da faixa 70-80% / 20-30%)
X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y,
    test_size=0.3, # 30% para teste
    random_state=42,
    stratify=Y 
)

print(f"Divis√£o Treino/Teste (70%/30%):")
print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"Y_train shape: {Y_train.shape}")
print(f"Y_test shape: {Y_test.shape}")

print("\n--- 4. Padroniza√ß√£o dos Dados (StandardScaler) ---")

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)

X_test_scaled = scaler.transform(X_test)

X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)

print("StandardScaler aplicado:")
print("  - Ajustado (fit) apenas no X_train.")
print("  - Transformado em X_train e X_test.")
print("M√©dia (deve ser pr√≥ximo a 0) e Desvio Padr√£o (deve ser pr√≥ximo a 1) para X_train_scaled:")
print(f"M√©dia: {X_train_scaled.mean().mean():.4f}")
print(f"Desvio Padr√£o: {X_train_scaled.std().mean():.4f}")

print("\n--- Processamento Conclu√≠do ---")
print("Os datasets X_train_scaled, X_test_scaled, Y_train, e Y_test est√£o prontos para a Modelagem.")

"""## 3) Treinamento dos Modelos

"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np

# Definir os shapes de X_train/X_test e Y_train/Y_test
n_samples = 569
n_features = 30
test_size = 0.3 # 171 samples
train_size = n_samples - test_size # 398 samples

# Se rodou o c√≥digo do passo 1.2, as vari√°veis X_train, X_test, Y_train, Y_test est√£o prontas.
# Dicion√°rio para armazenar modelos treinados
models = {}
# Dicion√°rio para armazenar resultados de acur√°cia
results = {}

print("--- 1. Inicializando Modelos ---")

# 1. Regress√£o Log√≠stica
models['LogisticRegression'] = LogisticRegression(max_iter=500, random_state=42)

# 2. SVM Linear
models['SVC_Linear'] = SVC(kernel='linear', random_state=42)

# 3. SVM Polinomial (Grau 2)
models['SVC_Poly_Degree_2'] = SVC(kernel='poly', degree=2, random_state=42)

# 4. SVM Polinomial (Grau 3)
models['SVC_Poly_Degree_3'] = SVC(kernel='poly', degree=3, random_state=42)

print(f"Total de modelos a serem treinados: {len(models)}")
print("-" * 50)

# --- 2. Treinamento e Avalia√ß√£o em Loop ---

for name, model in models.items():
    print(f"Treinando modelo: {name}...")

    # 2.1. Treinamento
    model.fit(X_train, Y_train) 

    # 2.2. Previs√£o no conjunto de Teste
    y_pred = model.predict(X_test)

    # 2.3. Avalia√ß√£o da Acur√°cia
    accuracy = accuracy_score(Y_test, y_pred) # Corrigido de y_test para Y_test
    results[name] = accuracy

    print(f"-> Treinamento conclu√≠do. Acur√°cia no Teste: {accuracy:.4f}")

    # 2.4. Salvando o modelo na mem√≥ria (no dicion√°rio 'models')
    # O modelo treinado j√° est√° salvo no dicion√°rio 'models'
    print(f"-> Modelo {name} salvo no dicion√°rio 'models'.")
    print("-" * 50)


# --- 3. Resultados Consolidados ---

print("--- 3. Resultados Consolidados de Acur√°cia ---")

results_df = pd.DataFrame(results.items(), columns=['Modelo', 'Acur√°cia'])
results_df = results_df.sort_values(by='Acur√°cia', ascending=False).reset_index(drop=True)

print(results_df.to_markdown(index=False))

best_model_name = results_df.iloc[0]['Modelo']
best_accuracy = results_df.iloc[0]['Acur√°cia']

print(f"\n‚úÖ O modelo com maior acur√°cia no conjunto de teste √© o **{best_model_name}** com **{best_accuracy:.4f}**.")

"""## 4) Avalia√ß√£o

"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
    roc_curve,
    auc
)
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

X_train = X_train_scaled
X_test = X_test_scaled

# --- 2. TREINAMENTO DOS MODELOS ---

models = {}

models['LogisticRegression'] = LogisticRegression(max_iter=500, random_state=42)
models['SVC_Linear'] = SVC(kernel='linear', random_state=42, probability=True)
models['SVC_Poly_Degree_2'] = SVC(kernel='poly', degree=2, random_state=42, probability=True)
models['SVC_Poly_Degree_3'] = SVC(kernel='poly', degree=3, random_state=42, probability=True)

print("--- üß† Treinamento dos Modelos Iniciado ---")
for name, model in models.items():
    model.fit(X_train, Y_train)
    print(f"‚úÖ Modelo {name} treinado.")
print("-" * 50)


# --- 3. AVALIA√á√ÉO DOS MODELOS (Etapa 4 + Opcional: ROC/AUC) ---

all_metrics = []
plt.figure(figsize=(10, 8))
plt.plot([0, 1], [0, 1], 'k--', label='Aleat√≥rio (AUC = 0.50)')

for name, model in models.items():
    # Previs√£o das classes e das probabilidades
    y_pred = model.predict(X_test)

    y_proba = model.predict_proba(X_test)[:, 1]

    # --- M√©tricas B√°sicas ---
    cm = confusion_matrix(Y_test, y_pred)
    report = classification_report(Y_test, y_pred, target_names=['Benigno (0)', 'Maligno (1)'], output_dict=True)

    acc = accuracy_score(Y_test, y_pred)
    prec = report['Maligno (1)']['precision']
    rec = report['Maligno (1)']['recall']
    f1 = report['Maligno (1)']['f1-score']

    # --- Curva ROC e AUC (Opcional) ---
    fpr, tpr, thresholds = roc_curve(Y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    # Plotar a Curva ROC
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')

    # Armazenar para a tabela comparativa
    all_metrics.append({
        'Modelo': name,
        'Acur√°cia': acc,
        'Precis√£o': prec,
        'Recall': rec,
        'F1-Score': f1,
        'AUC': roc_auc
    })

    # Impress√£o da Matriz de Confus√£o e M√©tricas
    print(f"\n\n======== üìä Avalia√ß√£o Detalhada: {name} ========")
    cm_df = pd.DataFrame(cm, index=['Real B (0)', 'Real M (1)'], columns=['Previsto B (0)', 'Previsto M (1)'])
    print("\n1. Matriz de Confus√£o:")
    print(cm_df.to_markdown())
    print(f"\n2. Acur√°cia: {acc:.4f}")
    print(f"3. Precis√£o (Maligno/1): {prec:.4f}")
    print(f"4. Recall (Maligno/1): {rec:.4f}")
    print(f"5. F1-score (Maligno/1): {f1:.4f}")
    print(f"6. AUC (Area Under the Curve): {roc_auc:.4f}")


# --- 4. Tabela Comparativa de Desempenho (Incluindo AUC) ---

print("\n\n" + "=" * 80)
print("             üèÜ Tabela Comparativa de Desempenho (Acur√°cia, Precis√£o, Recall, F1, AUC)")
print("=" * 80)

results_df = pd.DataFrame(all_metrics)
results_df = results_df.sort_values(by='AUC', ascending=False).reset_index(drop=True)

print(results_df.to_markdown(index=True, floatfmt=".4f"))


# --- 5. Visualiza√ß√£o da Curva ROC ---
plt.xlabel('Taxa de Falso Positivo (FPR)')
plt.ylabel('Taxa de Verdadeiro Positivo (TPR)')
plt.title('Curva ROC Comparativa dos Modelos')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

print("\n**Nota:** A AUC mede a capacidade de distin√ß√£o do modelo, onde 1.0 √© perfeito.")